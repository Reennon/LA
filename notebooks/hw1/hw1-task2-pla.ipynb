{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe44083c-b2d1-4370-a08c-53b19b8ec944",
   "metadata": {
    "id": "fe44083c-b2d1-4370-a08c-53b19b8ec944"
   },
   "outputs": [],
   "source": [
    "# We use torch and sklearn only on steps of fitting data\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from scipy.optimize import linprog\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EQznMLwjRzhi",
   "metadata": {
    "id": "EQznMLwjRzhi"
   },
   "source": [
    "# Problem 2: Separating hyperplanes and the Perceptron Learning Algorithm (3pts)\n",
    "### <div align=\"right\"> &copy; Yurii Yeliseev & Rostyslav Hryniv, 2022 </div>\n",
    "\n",
    "## Completed by:   \n",
    "*   Nazar Andrushko\n",
    "*   Roman Kovalchuk\n",
    "\n",
    "\n",
    "#### The aim of this task is to discuss a simple binary classification method for linearly separated classes. The Perceptron Learning Algorithm finds a ***separating hyperplane*** in finitely many steps and is based on a clear geometric update method. We will derive the upper bound on the number of iterations in PLA and implement it for digit classification for the MNIST database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BPiRUcHnhqxX",
   "metadata": {
    "id": "BPiRUcHnhqxX"
   },
   "source": [
    "## 1. Separating hyperplanes and classification (0.9 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "F8uu18FS0NVJ",
   "metadata": {
    "id": "F8uu18FS0NVJ"
   },
   "source": [
    "### 1.1. Binary classification.    \n",
    "A typical task of binary classification reads as follows. We are given the set of labelled (training) data $(\\mathbf{x}_k, y_k), k=1,2,\\dots, N$, where $\\mathbf{x}_k \\in \\mathbb{R}^d$ gives a data point and the label $y_k = \\pm1$ encodes the class (e.g. $y_k=1$ is the <font color='red'>''red''</font> class and $y_k=-1$ is the <font color='blue'>''blue''</font> one). The task is to find a classfier $f \\,:\\, \\mathbb{R}^d \\to \\pm1$ that would correctly recognize the classes, i.e. satisfy $y_k f(\\mathbf{x}_k) >0$ for all (or most) $k=1,2,\\dots,N$. This function can then be used to guess the class of new (unseen) data $\\mathbf{x}\\in\\mathbb{R}^n$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HqpK65XMSYul",
   "metadata": {
    "id": "HqpK65XMSYul"
   },
   "source": [
    "\n",
    "### 1.2. Separating hyperplane  \n",
    "The simplest case is when the red and blue classes are *linearly separable*, i.e., when there is a hyperplane $H: \\mathbf{w} \\cdot \\mathbf{x} + w_0 = 0$ separating the red and blue datapoints. Then  $f(\\mathbf{x}) = \\mathbf{w}\\cdot \\mathbf{x} + w_0$ is an affine classifier, so that $f(\\mathbf{x}_k)>0$ for red points and $f(\\mathbf{x}_k)<0$ for blue ones. Augmenting $\\mathbf{x}$ to $\\widehat{\\mathbf{x}} := (1, \\mathbf{x})$ and $\\widehat{\\mathbf{w}} = (w_0,\\mathbf{w})$, we recognize that $f(\\mathbf{x})= \\widehat{\\mathbf{x}}\\cdot \\widehat{\\mathbf{w}}$. Therefore, the angles between $\\widehat{\\mathbf{x}}$ and $\\widehat{\\mathbf{w}}$ are acute for red datapoints and obtuse for the blue ones. The task is therefore to find the *normal vector* $\\widehat{\\mathbf{w}}$ with this properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75612201-411f-48d9-8f36-629d8e8c5811",
   "metadata": {
    "id": "75612201-411f-48d9-8f36-629d8e8c5811",
    "tags": []
   },
   "source": [
    "### 1.3. The idea behind the Perceptron learning algorithm (PLA)\n",
    "\n",
    "To simplify the notations, in what follows we will omit the \"hats\" above the $(d+1)$-dimensional vectors $\\widehat{\\mathbf{x}}$ and $\\widehat{\\mathbf{w}}$.\n",
    "\n",
    "PLA is an iterative algorithm that updates the direction vector ${\\mathbf{w}}$ towards a misclassified example, one at a time.\n",
    "\n",
    "Let's recall that correctly classified vectors $\\mathbf{x}_j$ must satisfy the inequality\n",
    "$$\n",
    "  y_j ({\\mathbf{w}}\\cdot {\\mathbf{x}}_j) > 0.\n",
    "$$\n",
    "If a red $\\mathbf{x}_j$ is misclassified, then the angle between ${\\mathbf{w}}$ and ${\\mathbf{x}}_j$ is obtuse. The idea is that we should decrease the angle between them by updating ${\\mathbf{w}}$ to ${\\mathbf{w}} + {\\mathbf{x}}_j$ (see Figure 1). Likewise, if a blue $\\mathbf{x}_j$ is misclassified, then the angle between ${\\mathbf{w}}$ and ${\\mathbf{x}}_j$ is acute, and we increase it be replacing ${\\mathbf{w}}$ with ${\\mathbf{w}} - {\\mathbf{x}}_j$. In both cases, the update is $${\\mathbf{w}} \\mapsto {\\mathbf{w}} + y_j {\\mathbf{x}}_j$$\n",
    "\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title></title>\n",
    "</head>\n",
    "<body>\n",
    "    <img src=\"https://drive.google.com/uc?export=view&id=12rduejeedS8NxrxXkSBJkkcDH3lB0k-R\">\n",
    "\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "\n",
    "### 1.4. **PLA**\n",
    "\n",
    "The above considerations suggest the following **PLA**:\n",
    "1.   Start with ${\\mathbf{w}}_0=\\mathbf{0}$ and classify the points\n",
    "2.   Take an arbitrary misclassified point\n",
    "3.   Update the ${\\mathbf{w}}$\n",
    "4.   Update the classification\n",
    "5.   Repeat 2-4 until there are misclassified points.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oOn-vs9ye4B2",
   "metadata": {
    "id": "oOn-vs9ye4B2"
   },
   "source": [
    "### 1.5. **PLA**: proof of convergence (0.9 pts)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#### **1.5.1 (0.3 pts)** Analyze the PLA update step  \n",
    "Prove that by updating ${\\mathbf{w}}$, we are decreasing or increasing (as required) the angle between ${\\mathbf{w}}$ and ${\\mathbf{x}}_j$.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "## First case\n",
    "The cosine of the angle between $w$ and $x_j$ is given by:\n",
    "\n",
    "$$ \\text{cos of angle between } w \\text{ and } x_j = \\frac{(w, x_j)}{||w|| \\cdot ||x_j||} = \\text{old\\_cosine} $$\n",
    "\n",
    "The cosine of the angle after updating is:\n",
    "\n",
    "$$ \\text{cos of Angle after updating} = \\frac{(w + y_j \\cdot x_j, x_j)}{||w + y_j \\cdot x_j|| \\cdot ||x_j||} = \\text{updated\\_cosine} $$\n",
    "\n",
    "Let's consider that $ x_j $ is a red point and is misclassified. Therefore, the angle between $ x_j $ and $ w $ is obtuse, and we need to show that the angle becomes more acute.\n",
    "\n",
    "Given: $ (w, x_j) < 0 $ and $ y_j = 1$\n",
    "\n",
    "Now let's see what happens with $( {updated\\_cosine} - {old\\_cosine} )$:\n",
    "\n",
    "1. Since (triangle ineq. ):\n",
    "$$ \\frac{((w, x_j) + (x_j, x_j))}{||w+x_j||||x_j||} > \\frac{((w, x_j) + (x_j, x_j))}{(||w|| + ||x_j||)||x_j||} $$\n",
    "\n",
    "2. Then we can proof that and we will show that $( {updated\\_cosine} - {old\\_cosine} ) > 0$, so the angle is more acute.\n",
    "\n",
    "$$  \\frac{((w, x_j) + (x_j, x_j))}{(||w|| + ||x_j||)||x_j||} > \\frac{(w, x_j)}{||w||||x_j||} \\text{   (want to proof) } $$ \n",
    "\n",
    "3. Bring to the common denominator : \n",
    "\n",
    "\n",
    "$$  \\frac{((w, x_j)||w|| + ||x_j||^2||w||)}{(||w|| + ||x_j||)||x_j||||w||} > \\frac{(w, x_j)(||w|| + ||x_j||)}{||w||||x_j||(||w|| + ||x_j||)} $$\n",
    "\n",
    "4. Which is the same as : (since denominator is > 0)\n",
    "\n",
    "$$  ((w, x_j)||w|| + ||x_j||^2||w||) > (w, x_j)(||w|| + ||x_j||)$$\n",
    "\n",
    "\n",
    "5. But ||x_j||^2||w|| > 0, so we can remove it from the left side of equation, and if it will hold, then 4. will hold.\n",
    "\n",
    "$$  ((w, x_j)||w||) > (w, x_j)(||w|| + ||x_j||)$$\n",
    "\n",
    "6. Divide by (w, x_j), which is less than zero. \n",
    "\n",
    "\n",
    "$$ ||w|| < ||w|| + ||x_j||$$\n",
    "\n",
    "\n",
    "Which is true. Therefore, from 6 we know that 5 is true, from 5 -> 4, and so on, so the initial equation 1. is true.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Therfore $\\text{updated\\_cosine}  - \\text{old\\_cosine} > 0$ therefore angle between $w$ and $x_j$ is more acute.\n",
    "\n",
    "\n",
    "## Second case\n",
    "??\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5680473-6119-4831-8990-ff6b3ac69e83",
   "metadata": {
    "id": "e5680473-6119-4831-8990-ff6b3ac69e83"
   },
   "source": [
    "#### **Assumptions and notations**\n",
    "\n",
    "***Assumption on linear separability*** There exists an ${\\mathbf{w}^{\\star}} \\in \\mathbb{R}^{d+1}$ of unit length and $\\gamma > 0$ such that $$y_k\\, {\\mathbf{x}}_k\\cdot {\\mathbf{w}}^{\\star} \\ge \\gamma, \\qquad k=1,2,\\dots, n.$$ The value $\\gamma$ determines the width of the *separating slab* free of any datapoints. The larger $\\gamma$, the wider the slab and the more robust the classifier is to noise in data.  \n",
    "\n",
    "We also denote by $R$ the maximum norm of $\\mathbf{x}_k$\n",
    "\n",
    "***Theorem on PLA convergence.*** The PLA makes at most $\\frac{R^2}{\\gamma^2}$ updates, after which it returns a separating hyperplane.\n",
    "\n",
    "***Proof.*** Should the algorthm terminate, then the resulting ${\\mathbf{w}}$ determines a separating hyperplane. Thus it suffices to show that the algorithm terminates after at most $\\frac{R^2}{\\gamma^2}$ updates. The approach is to get upper and lower bounds on the norm of the $k^{\\mathrm{th}}$ update ${\\mathbf{w}}_k$ of the weighting vector ${\\mathbf{w}}$, starting with ${\\mathbf{w}}_0 = \\mathbf{0}$.\n",
    "\n",
    "Assume that $k\\ge 1$ and ${\\mathbf{x}}_j$ is a misclasssified point on iteration $k$; then\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbf{w}_{k+1} \\cdot {\\mathbf{w}}^{\\star} &=\\left({\\mathbf{w}}_k + y_j \\mathbf{x}_j\\right) \\cdot {\\mathbf{w}}^{\\star} \\\\\n",
    "&={\\mathbf{w}}_k \\cdot {\\mathbf{w}}^{\\star}+y_j\\left({\\mathbf{x}}_j \\cdot {\\mathbf{w}}^{\\star}\\right) \\\\\n",
    "&>{\\mathbf{w}}_k \\cdot {\\mathbf{w}}^{\\star} + \\gamma\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **1.5.2. (0.3 pts)** Explain by induction that ${\\mathbf{w}}_{k} \\cdot {\\mathbf{w}}^{\\star}> k \\gamma$.\n",
    "\n",
    "---\n",
    "\n",
    "1. Base step:\n",
    "k = 1\n",
    "\n",
    "$w_1 * w^{\\star} > w_0 * w^{\\star} + \\gamma = 1 * \\gamma$\n",
    "\n",
    "2. Induction step.\n",
    "Assume that statement is correct for $1 <= k <= n$, therefore $w_n * w^{\\star} > k * \\gamma$, then let's show that it is correct for k = n +1.\n",
    "\n",
    " $w_{n+1} * w^{\\star} > w_n * w^{\\star} + \\gamma >\\text{ |by our assumption|  } > n * \\gamma + \\gamma = (n+1)*\\gamma.$\n",
    "\n",
    "3. By confirming the base case and demonstrating the inductive step, we establish that the statement is true for all integers n ≥ 1.\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BfKkTkx2YTrb",
   "metadata": {
    "id": "BfKkTkx2YTrb"
   },
   "source": [
    "As a result, we see that\n",
    "$$\\|\\mathbf{w}_k\\| \\ge {\\mathbf{w}}_{k} \\cdot {\\mathbf{w}}^{\\star}> k \\gamma\\tag{1}$$\n",
    "\n",
    "To obtain the upper bound, we argue that\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\left\\|\\mathbf{w}_{k+1}\\right\\|^2 &=\\left\\|\\mathbf{w}_k+y_j \\mathbf{x}_j\\right\\|^2 \\\\\n",
    "&=\\left\\|\\mathbf{w}_k\\right\\|^2+\\left\\|y_j \\mathbf{x}_j\\right\\|^2+2\\left(\\mathbf{w}_k \\cdot \\mathbf{x}_j\\right) y_j \\\\\n",
    "&=\\left\\|\\mathbf{w}_k\\right\\|^2+\\left\\|\\mathbf{x}_j\\right\\|^2+2\\left(\\mathbf{w}_k \\cdot \\mathbf{x}_j\\right) y_j\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **1.5.3. (0.3 pts)** Derive the lower bound\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\left\\|\\mathbf{w}_{k+1}\\right\\|^2\n",
    "&\\le\\left\\|\\mathbf{w}_k\\right\\|^2+\\left\\|\\mathbf{x}_j\\right\\|^2 \\\\\n",
    "&\\le\\left\\|\\mathbf{w}_k\\right\\|^2+R^2\n",
    "\\end{aligned}\n",
    "$$\n",
    "and use induction to conclude that\n",
    "$$\n",
    "\\left\\|\\mathbf{w}_{k}\\right\\|^2 \\le k\\, R^2 \\tag{2}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "1. Base case.\n",
    "k = 0\n",
    "\n",
    "$ ||w_0||^2 = 0 <= 0*R^2$\n",
    "\n",
    "2. Inductive step\n",
    "\n",
    "Assume that statement is correct for $0 <= k <= n$, therefore $|w_n|^2 <= nR^2$ , then let's show that it is correct for k = n +1.\n",
    "\n",
    "$ ||w_{n+1}||^2 <= ||w_n||^2 + R^2 <= nR^2 + R^2 = (n+1)R^2 $\n",
    "\n",
    "3. By confirming the base case and demonstrating the inductive step, we establish that the statement is true for all integers n ≥ 0.\n",
    "\n",
    "---\n",
    "\n",
    "Together, (1) and (2) yield\n",
    "$$\n",
    "k^2 \\gamma^2<\\left\\|\\mathbf{w}_{k}\\right\\|^2 \\le k R^2,\n",
    "$$\n",
    "which implies the bound $k<\\frac{R^2}{\\gamma^2}$ and finishes the proof."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4vq40CCjb4tp",
   "metadata": {
    "id": "4vq40CCjb4tp"
   },
   "source": [
    "## 2. PLA implementation on MNIST dataset (1.8 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69405653-4bb7-4a5a-a6ab-6d06f81e2452",
   "metadata": {
    "id": "69405653-4bb7-4a5a-a6ab-6d06f81e2452"
   },
   "source": [
    "### 2.1. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25024833-b7ae-48a4-b2d2-254aedb9e1ff",
   "metadata": {
    "id": "25024833-b7ae-48a4-b2d2-254aedb9e1ff"
   },
   "source": [
    "`train_data` is torch dataset object where images and targets lie inside `train_data.data` and `train_data.targets` respectively. To convert to numpy array you can use `.numpy()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "689dbfa9-1ed2-4baa-b0f0-8c094fa9a972",
   "metadata": {
    "id": "689dbfa9-1ed2-4baa-b0f0-8c094fa9a972"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 10301645.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 20413834.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 10223999.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 9963665.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.MNIST(root='data', train=True, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0a6dd4-0ffe-4f59-bfad-b33824243772",
   "metadata": {
    "id": "ab0a6dd4-0ffe-4f59-bfad-b33824243772"
   },
   "source": [
    "### 2.2 Take 2 digits samples **(0.3 pts)**\n",
    "\n",
    "First of all you need to take only two digits samples from the dataset and convert the targets properly for the PLA. Choose the two digits based on the sum of your birthdays (e.g. 2 and 4 if it is 24; take 4 and 5 if it is 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cf9e98a-daff-4c94-9019-ace288e89bc9",
   "metadata": {
    "id": "8cf9e98a-daff-4c94-9019-ace288e89bc9"
   },
   "outputs": [],
   "source": [
    "def filter_data(train_data, digit_1, digit_2):\n",
    "    \"\"\"\n",
    "    Take only digit_1 and digit_2 from the dataset and transform labels\n",
    "    Args:\n",
    "        train_data: torchvision.datasets.mnist.MNIST\n",
    "        digit_1: int (from 0 to 9)\n",
    "        digit_2: int (from 0 to 9)\n",
    "\n",
    "    Returns:\n",
    "        train_data: torchvision.datasets.mnist.MNIST or np.array\n",
    "    \"\"\"\n",
    "    # ========= YOUR CODE STARTS HERE ========= #\n",
    "    digits_cls = torch.tensor([digit_1, digit_2])\n",
    "    indices = torch.isin(train_data.targets, digits_cls)\n",
    "    train_data.data, train_data.targets = train_data.data[indices], train_data.targets[indices]\n",
    "    # ========== YOUR CODE ENDS HERE ========== #\n",
    "    \n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dee2eaa6-498f-4174-875a-501548d56113",
   "metadata": {
    "id": "dee2eaa6-498f-4174-875a-501548d56113"
   },
   "outputs": [],
   "source": [
    "train_data = filter_data(train_data, 1, 2)\n",
    "\n",
    "mapper = {1:1,2:-1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IFga5wKx5qLn",
   "metadata": {
    "id": "IFga5wKx5qLn"
   },
   "source": [
    "### 2.3 Take a smaller subset and divide it into train and test sets **(0.3 pts)**\n",
    "\n",
    "\n",
    "Since the dataset is big, you need to use only part of it in this task (take\n",
    "~20-30% of the whole dataset for further processing).\n",
    "\n",
    "1. Properly subdivide dataset\n",
    "2. Calculate number samples in each class for test and train\n",
    "\n",
    "***Note***: you need to have same distributions inside train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "13cxSAQd5qLo",
   "metadata": {
    "id": "13cxSAQd5qLo"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "def split_dataset(train_data):\n",
    "    \"\"\"\n",
    "    Split dataset into train and test parts.\n",
    "\n",
    "    !Hint: You can use train_test_split from sklearn for that\n",
    "\n",
    "    Args:\n",
    "        train_data: torchvision.datasets.mnist.MNIST or np.array\n",
    "\n",
    "    Returns:\n",
    "        X_train: Array of shape (N, 28, 28), images from the train set\n",
    "        y_train: Array of shape (N), labels from the train set\n",
    "\n",
    "        X_test: Array of shape (N, 28, 28), images from the test set\n",
    "        y_test: Array of shape (N), labels from the test set\n",
    "    \"\"\"\n",
    "    # ========= YOUR CODE STARTS HERE ========= #\n",
    "    all_idx = list(range(len(train_data)))\n",
    "    subsample = random.sample(all_idx,int(len(all_idx)*0.3))\n",
    "\n",
    "    mapped_targets = torch.tensor([mapper[item.item()] for item in train_data.targets])\n",
    "\n",
    "    small_train_data, small_train_targets = train_data.data[subsample], mapped_targets[subsample]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(small_train_data,small_train_targets)\n",
    "    # ========== YOUR CODE ENDS HERE ========== #\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4pT-osLT5qLo",
   "metadata": {
    "id": "4pT-osLT5qLo"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_dataset(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "KV4wznVX5qLo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KV4wznVX5qLo",
    "outputId": "2ec93ca1-af38-414f-fc25-349053e2c1b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in train: 2857 \n",
      "Classes number in train: 1524, 1333 \n",
      "Number of samples in test: 953 \n",
      "Classes number in test: 538, 415\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of samples in train: {len(X_train)} \\n\\\n",
    "Classes number in train: {torch.sum(y_train == 1)}, {torch.sum(y_train == -1)} \\n\\\n",
    "Number of samples in test: {len(X_test)} \\n\\\n",
    "Classes number in test: {torch.sum(y_test == 1)}, {torch.sum(y_test == -1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swE73GJ76GxU",
   "metadata": {
    "id": "swE73GJ76GxU"
   },
   "source": [
    "### 2.4 Visualize samples for the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6jc6fJqX6Gxe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "id": "6jc6fJqX6Gxe",
    "outputId": "ebe6e978-ea59-41fe-bc61-2c52f565ef08"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIUAAAGrCAYAAABe0idMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAsCElEQVR4nO3de5RV5X038OcACl4GFCHKKIZGk2gtYESjMcZhqo0mipqYVReJJasXu7wEU0UrKC7ES6vx0mg0tCa2Uhea1qj1Al5oIigam7Ter8RUERi0DspFvKDMef9I3+ZN3+c5zB7OzJl9ns9nLf/57tn7+R3cz+yZn1t+lWq1Wg0AAAAAZGVAowsAAAAAoO9pCgEAAABkSFMIAAAAIEOaQgAAAAAZ0hQCAAAAyJCmEAAAAECGNIUAAAAAMqQpBAAAAJAhTSEAAACADGkKAQAAAGRIU6jBVq1aFaZPnx7a29tDS0tLqFQqYdGiRY0uC9iMd955J8yaNSsceeSRYfjw4aFSqYQbb7yx0WUBBXgGQzl5BkP5eQb3H5pCDfbSSy+Fyy67LKxcuTKMHTu20eUA3dTZ2RkuvPDC8MILL4Tx48c3uhygBzyDoZw8g6H8PIP7D02hBpswYUJYvXp1WLp0aTjzzDMbXQ7QTaNGjQqrVq0Ky5YtC5dffnmjywF6wDMYyskzGMrPM7j/GNToAnLX0tLS6BKAHhg8eHDYZZddGl0GsAU8g6GcPIOh/DyD+w9vCgEAAABkSFMIAAAAIEOaQgAAAAAZ8ncK9ZGNGzeGt95667eykSNHhoEDBzaoIgDIg2cwADSGZ3D/502hPvLoo4+GUaNG/dY/y5cvb3RZAND0PIMBoDE8g/s/bwr1kfHjx4eFCxf+VmZqAgD0Ps9gAGgMz+D+T1Ooj+y4447h8MMPb3QZAJAdz2AAaAzP4P5PU6gfuPjii0MIITz33HMhhBBuuummsGTJkhBCCDNnzmxYXUBt1157bVizZk3o6OgIIYRw9913hxUrVoQQQpg6dWoYNmxYI8sDusEzGMrJMxjKzzO4f6hUq9Vqo4vIXaVSSR7zrwf6rzFjxoRly5ZFj73yyithzJgxfVsQUJhnMJSTZzCUn2dw/6ApBAAAAJAh08cAAAAAMqQpBAAAAJAhTSEAAACADGkKAQAAAGRIUwgAAAAgQ5pCAAAAABka1J0v6urqCh0dHaGlpSVUKpXergnqplqthvXr14fW1tYwYEC+PVB7mLKyh+1fysv+/TV7mLKyh+1fyqvI/u1WU6ijoyOMHj26LsVBIyxfvjzstttujS6jYexhyi7nPWz/UnY5798Q7GHKL+c9bP9Sdt3Zv91q+ba0tNSlIGiU3O/h3D8/5ZfzPZzzZ6c55H4P5/75Kb+c7+GcPzvNoTv3cLeaQl6Vo+xyv4dz//yUX873cM6fneaQ+z2c++en/HK+h3P+7DSH7tzDef7PoQAAAACZ0xQCAAAAyJCmEAAAAECGNIUAAAAAMqQpBAAAAJAhTSEAAACADGkKAQAAAGRIUwgAAAAgQ5pCAAAAABnSFAIAAADIkKYQAAAAQIY0hQAAAAAypCkEAAAAkCFNIQAAAIAMaQoBAAAAZEhTCAAAACBDmkIAAAAAGdIUAgAAAMiQphAAAABAhjSFAAAAADKkKQQAAACQIU0hAAAAgAwNanQBAL1phx12SB678847o/lTTz0VzU8//fR6lAT8L2PGjInmCxcuTJ7ziU98opeq+Y2HHnoomh9xxBHRfOPGjb1ZDtAE5syZE81PPvnk5DkffPBBNB8yZEhdagLy5k0hAAAAgAxpCgEAAABkSFMIAAAAIEOaQgAAAAAZ0hQCAAAAyJDpY5tx9NFHJ49ts8020Tw17WjmzJnRvFKpJNeoVqvp4urk7LPPjuZ33313NH/vvfd6sxyoqxEjRiSPHXLIIdF8zZo10Xy77baL5hs2bChcFzSzvfbaK5pPnTo1mk+ZMiWap56zIfTN8/HQQw+N5qeddlo0v/7666O57xGQn5aWlmj+5ptvRvOurq7ktR555JFoPnHixGi+aNGimrXBlho6dGg0v/TSS6P5L37xi2h+1VVXJdc455xzovnbb78dze+///5ovm7duuQa/Jo3hQAAAAAypCkEAAAAkCFNIQAAAIAMaQoBAAAAZEhTCAAAACBDlWo3xnesW7cuDBs2rC/qKST1t/qHEMI+++wTzY899tho3tbWFs333Xff5Bpbb711urgCGj19LLX+5ZdfHs2nT5/em+X0irVr1yb/lvwc9Nc93Bf23HPP5LGXXnopmqf2xJVXXhnNUxP8qJ+c93B/3b+pCWMhhLBgwYJovvvuuxdao7Ozs/AaqSkjv/rVr6L53/zN3yTXSH0vSD2b77333mh+4oknJtdYu3Zt8lizyHn/htB/9zD1MWbMmGj+zDPPRPMBA+L/Tf6aa65JrjFr1qxovnHjxtrF1UnOezjn/bvffvsljz322GPRfNCgYsPN6/l7cOpnhlGjRiXP2bRpU6E1yqg7+9ebQgAAAAAZ0hQCAAAAyJCmEAAAAECGNIUAAAAAMqQpBAAAAJAhTSEAAACADBWbGdcgBx10UDS/6KKLkue0t7cXWqPo2Nl6WrFiRfJYanzce++9F80/9rGP1aWmEEL4+Mc/XrdrQaPUGmn90EMPRfOJEydG8+OPPz6a/8M//ENyjeeffz5dHJTYYYcdljyWGj3f0dERzW+++eZoPmfOnOQay5Ytq1Hd/2/gwIHRvNY43Frj6mO+9KUvRfNLL700ec4pp5xSaA2g7x1xxBHJY9OnT4/m2267bTRfsGBBNJ8xY0bxwqAXjR07Nnks9UxtpBEjRkTzM844I3nOFVdc0VvllIo3hQAAAAAypCkEAAAAkCFNIQAAAIAMaQoBAAAAZEhTCAAAACBDpZg+Nnr06GhedMJYX5k7d240f+aZZ6L5d7/73eS12traovnSpUuj+T333BPNx48fn1wDmtmaNWuSx6699tpontp3qYl8J554YnKNc889N10clNjJJ59c+Jyf//zn0Tw1vaeeNm3aFM2vueaa5Dlbb711NL/kkkuieWoay8iRIzdTHdAfDB8+PJqnfi4IIYRDDz00mi9ZsiSaX3nllcULgwYYNCjdKkj9DPCzn/2s0Bqf/vSnk8emTJkSzSdNmlRojcsuuyx5bPvtt4/mF1xwQaE1ys6bQgAAAAAZ0hQCAAAAyJCmEAAAAECGNIUAAAAAMqQpBAAAAJChUkwf++UvfxnN33jjjeQ5//Ef/xHNU1O7zjrrrOKF9YHFixdH84MOOiia77vvvoXXGDAg3hvsr38mUC+33XZbNK9UKtG8Wq1G8+OPPz65huljNKsHHnggeWzvvfeO5jvuuGM0T03/eOedd4oXVkdXXHFFNJ85c2Y0T30OoH8ZN25cNJ8/f340b21tTV4r9X3q/PPPj+YPPfTQZqqD/uGGG27o9TWeffbZ5LHUVO3UBNAzzzwzmqd+rg8hhN/7vd+rUV0+vCkEAAAAkCFNIQAAAIAMaQoBAAAAZEhTCAAAACBDmkIAAAAAGSrF9LEnn3wymteatJWaBPDee+/VoaK+M3r06Gj+3e9+N5qnpiPVcuqpp0bz119/vfC1IEe1ppIcc8wx0fyuu+7qrXKgT1x33XXJY5/73OeieWdnZzTfaqut6lJTfzVv3rxGlwD8P84+++xoXut5nmLKGPSODz74IJqnpgSmpo/V8uUvfzma77nnntH85ZdfLrxGGXhTCAAAACBDmkIAAAAAGdIUAgAAAMiQphAAAABAhjSFAAAAADKkKQQAAACQoVKMpE958803G11Cr0uNsd1///0LXefVV19NHpszZ06ha0Gzq1arhb5+2223TR7bfffdt7Qc6Jf+8z//M3ns4IMP7sNKek9LS0s0r1Qq0XzJkiXR/Kc//WndagJ+28iRI5PHfvCDH0Tz9vb2aL5u3bpofsoppyTXuO+++2pUB9Tb888/H803bNgQzbfbbrvktVLn1PoZpxl5UwgAAAAgQ5pCAAAAABnSFAIAAADIkKYQAAAAQIY0hQAAAAAyVOrpY83ixBNPTB77zGc+U+hamzZtiuZ//dd/Xeg6kLOHH344mn/hC18ofK3UlCKg/5s2bVo0T00ySU0rWbt2bd1qglylpoylJvWGEMJhhx0Wze+8885oPnPmzGiemnYE9L033ngjmr/22mvRfO+9905eKzWhu6urq3BdZeZNIQAAAIAMaQoBAAAAZEhTCAAAACBDmkIAAAAAGdIUAgAAAMiQ6WN96Nhjj43mc+fOTZ5TrVYLrfG3f/u30fyGG24odB3I2ZVXXhnN99tvv2i+7bbbJq+VmmTyve99r3hhQN0dccQRyWPnn39+NC/6bAa23NChQ6P5pz71qcLXevnll6O5KWOwZWr9TBzz7rvvFl5jyJAh0Xy33XYrfK1HHnmk8DnNyJtCAAAAABnSFAIAAADIkKYQAAAAQIY0hQAAAAAypCkEAAAAkCHTx7ZAa2trNJ8/f340HzduXDQfMCDdm+vq6orml156aTQ/77zzktcCuueuu+6K5qtWrYrme+yxR/JaI0aMqEtNQO9oa2tLHks9n1PP5ocffrguNUHOJk+eHM3/8i//MpqPHj06ea1p06ZF83/8x38sXhjwP84555xofvTRR0fzDRs2RPPTTz89ucbSpUuj+YwZM6J5S0tL8lop999/f+FzmpE3hQAAAAAypCkEAAAAkCFNIQAAAIAMaQoBAAAAZEhTCAAAACBDmkIAAAAAGTKSfjNqjbm89dZbo/nYsWOjebVajeap0bYhhHDxxRdH80suuSR5DgDkavvtt4/mP/7xj6P5oYcemrxW6vn89NNPR/Pbb799M9VB32tvb4/mDz30UPKcTZs29VY5/2P48OHRfPbs2dF8jz32iOYvvvhico2HH344mr/11lubqQ7ykRrlftNNNyXPmTRpUjSvVCqF1n7kkUeSxzo7O6P5zjvvXGiN1O/gIYSwdu3aQtdqVt4UAgAAAMiQphAAAABAhjSFAAAAADKkKQQAAACQIU0hAAAAgAyZPvbfWltbo3lqwlgIIey///51WfvSSy9NHps3b14037hxY13WBrovNVGh1qSF1LG2trZovnjx4uKFAf8jNWnp8MMPr9saRx11VDQ3xYT+6MEHH2zY2hMnTkwe+853vhPNU1PGHn/88Wh+xBFHJNcwZQw275vf/GY0P+aYY3p97Z122qlHx4pYsWJF8tjuu+8ezZ9//vlovmbNmnqU1O94UwgAAAAgQ5pCAAAAABnSFAIAAADIkKYQAAAAQIY0hQAAAAAyZPrYf5s/f340Hzt2bK+vveeeeyaP3XnnndH86aefrtv6Z511VqGv/+CDD6L5f/3Xf9WjHOi3qtVqobzWsa9+9avR3PQx6J5JkyZF87lz59ZtjTPOOCOav/7663VbA5rBDjvsEM2nT5+ePGfChAnRfMGCBdH8sssui+YmjMGW+drXvlb4nNQU7tNOOy2a//Ef/3HhNepl9OjRyWM333xzNH/yySej+XHHHRfNX3vttaJl9SveFAIAAADIkKYQAAAAQIY0hQAAAAAypCkEAAAAkCFNIQAAAIAMlXr62JgxY5LHvvWtbxW61rhx46J5ralC9VLrb3xPrf/JT36y19dPrb1q1apofvTRRyfXeOqpp4oXBkDWhg0bljx29tlnR/OhQ4cWWuP73/9+8tg111xT6FqQq9QEnz/4gz8ofK0ZM2ZE82effbbwtYDf2HfffaP5oYceGs1TE7hCSP9ud9JJJ0Xzzs7OaJ56lvfEhx9+GM3feOON5Dm77bZbofydd94pXlgJeFMIAAAAIEOaQgAAAAAZ0hQCAAAAyJCmEAAAAECGNIUAAAAAMqQpBAAAAJChfjWSfsKECdE8NV5+ypQpdVt7wIB4f6yrq6tuaxRdu9Hrp9ZubW2N5o8//nhyjTvvvDOaf/WrX91MdQA0u2OOOSaan3vuuclz9t9//2i+cePGaP5v//Zv0fzKK6/cTHXA/3X11VdH8y984QuFrzVz5sxovnLlysLXAupvq622Sh4bPHhwNB84cGA0P+iggwqvv2HDhmj+53/+59H84Ycfjubjx49PrjFoULwd0tLSEs0/9rGPRfO33noruUYZeFMIAAAAIEOaQgAAAAAZ0hQCAAAAyJCmEAAAAECGNIUAAAAAMtSvpo8tXLgwmg8dOjSaV6vVuq394osvRvMnn3yybmukVCqV5LHUZ1y2bFk0v+mmm6J5asJDrfWPOuqoaL7NNtskr5WSmiwDZZLaK7X2cE/OgWY1adKkaP73f//30XyHHXYovMbbb78dzU855ZRoXuuZttdeexVa+zOf+Uw0/93f/d3kOfPmzYvm77//fjR/9dVXC9UEPdHe3h7NTzrppGiemkS0aNGi5Bpz5syJ5mvWrKlZG9Azu+66a6Gv32effZLHUhPAvvKVr0Tz1ITCDz/8MLnGH/3RH0Xzf/mXf0meE7NixYpCX58jbwoBAAAAZEhTCAAAACBDmkIAAAAAGdIUAgAAAMiQphAAAABAhvrV9LHUtIHU9LFali5dGs1vvPHGaP5P//RP0Tw15atsJk+eXPic/fbbL5pPmzYtmu++++7Ja919992F14f+JjUNsNYkxJ6cA2V3yCGHRPO5c+dG854851N23nnnaP7ss88WvlZqSmA99++MGTOieWdnZzS/7777ovm6deuSa5x77rnR/J133tlMdTSz1MSwEEKYPn16oXMeeuihaJ6aRBRC7XsWqL+VK1fW7VpXXXVVoa9fvXp1NE89A0MoPmWMnvOmEAAAAECGNIUAAAAAMqQpBAAAAJAhTSEAAACADGkKAQAAAGSoX00fO/LII6P5uHHjCl/rsccei+YrVqwofK1cPf7449H8G9/4Rh9XAs0nNVkImsEnPvGJaF7PKWMpXV1d0bwnk7aGDBkSzVPTxwYMiP+3toEDBybXSJ0zYsSIaH7iiScmr5WSmg563HHHFb4WzWP+/PnJY+3t7dF806ZN0fzrX/96NDdhDPKS+h4xderUaP6jH/2oN8uhm7wpBAAAAJAhTSEAAACADGkKAQAAAGRIUwgAAAAgQ5pCAAAAABnSFAIAAADIUL8aSb906dJCOUBfuuiii6L5n/zJnyTPue2226L5tddeW5eaoD96/PHHo/m8efOi+dq1a6P5ypUrC6+dGj1/3XXXFb7WQQcdVOjrd9ppp2je2tqaPGf48OHRPPV9ZY899ihUUwgh3H///YXPofkdcsghhc854YQTovmqVau2tBygl6WeqT/72c+i+f7775+81qJFi6L5lClTovkbb7xRuzgayptCAAAAABnSFAIAAADIkKYQAAAAQIY0hQAAAAAypCkEAAAAkKFKtVqtbu6L1q1bF4YNG9YX9UCvWLt2bRg6dGijy2gYe5iyy3kP27+UXc77NwR7mPLLeQ/nsH8HDYoPJL/wwguT58yaNSuaf/jhh3Wpifrpzv71phAAAABAhjSFAAAAADKkKQQAAACQIU0hAAAAgAxpCgEAAABkKP5XjQMAAABN7aOPPorm5557bh9XQqN4UwgAAAAgQ5pCAAAAABnSFAIAAADIkKYQAAAAQIY0hQAAAAAypCkEAAAAkCFNIQAAAIAMaQoBAAAAZEhTCAAAACBDmkIAAAAAGdIUAgAAAMiQphAAAABAhjSFAAAAADKkKQQAAACQIU0hAAAAgAxpCgEAAABkSFMIAAAAIEPdagpVq9XergN6Ve73cO6fn/LL+R7O+bPTHHK/h3P//JRfzvdwzp+d5tCde7hbTaH169dvcTHQSLnfw7l/fsov53s4589Oc8j9Hs7981N+Od/DOX92mkN37uFKtRuto66urtDR0RFaWlpCpVKpS3HQF6rVali/fn1obW0NAwbk+39L2sOUlT1s/1Je9u+v2cOUlT1s/1JeRfZvt5pCAAAAADSXPFu+AAAAAJnTFAIAAADIkKYQAAAAQIY0hQAAAAAypCkEAAAAkCFNIQAAAIAMaQoBAAAAZEhTCAAAACBDmkIAAAAAGdIUAgAAAMiQphAAAABAhjSFGmzVqlVh+vTpob29PbS0tIRKpRIWLVrU6LKAzXjnnXfCrFmzwpFHHhmGDx8eKpVKuPHGGxtdFlCAZzCUmz0M5WX/9h+aQg320ksvhcsuuyysXLkyjB07ttHlAN3U2dkZLrzwwvDCCy+E8ePHN7ocoAc8g6Hc7GEoL/u3/9AUarAJEyaE1atXh6VLl4Yzzzyz0eUA3TRq1KiwatWqsGzZsnD55Zc3uhygBzyDodzsYSgv+7f/GNToAnLX0tLS6BKAHhg8eHDYZZddGl0GsAU8g6Hc7GEoL/u3//CmEAAAAECGNIUAAAAAMqQpBAAAAJAhf6dQH9m4cWN46623fisbOXJkGDhwYIMqAoA8eAZDudnDUF72b//nTaE+8uijj4ZRo0b91j/Lly9vdFkA0PQ8g6Hc7GEoL/u3//OmUB8ZP358WLhw4W9lJhcBQO/zDIZys4ehvOzf/k9TqI/suOOO4fDDD290GQCQHc9gKDd7GMrL/u3/NIX6gYsvvjiEEMJzzz0XQgjhpptuCkuWLAkhhDBz5syG1QXUdu2114Y1a9aEjo6OEEIId999d1ixYkUIIYSpU6eGYcOGNbI8oBs8g6Hc7GEoL/u3f6hUq9Vqo4vIXaVSSR7zrwf6rzFjxoRly5ZFj73yyithzJgxfVsQUJhnMJSbPQzlZf/2D5pCAAAAABkyfQwAAAAgQ5pCAAAAABnSFAIAAADIkKYQAAAAQIY0hQAAAAAypCkEAAAAkKFB3fmirq6u0NHREVpaWkKlUuntmqBuqtVqWL9+fWhtbQ0DBuTbA7WHKSt72P6lvOzfX7OHKSt72P6lvIrs3241hTo6OsLo0aPrUhw0wvLly8Nuu+3W6DIaxh6m7HLew/YvZZfz/g3BHqb8ct7D9i9l1539262Wb0tLS10KgkbJ/R7O/fNTfjnfwzl/dppD7vdw7p+f8sv5Hs75s9McunMPd6sp5FU5yi73ezj3z0/55XwP5/zZaQ6538O5f37KL+d7OOfPTnPozj2c5/8cCgAAAJA5TSEAAACADGkKAQAAAGRIUwgAAAAgQ5pCAAAAABnSFAIAAADIkKYQAAAAQIY0hQAAAAAypCkEAAAAkCFNIQAAAIAMaQoBAAAAZEhTCAAAACBDmkIAAAAAGdIUAgAAAMiQphAAAABAhjSFAAAAADKkKQQAAACQIU0hAAAAgAxpCgEAAABkSFMIAAAAIEOaQgAAAAAZ0hQCAAAAyNCgRhfQW4YNGxbNBw4cGM332muvaD5+/PjkGj/96U+j+SmnnLKZ6rpv8eLF0fyBBx6I5hs2bKjb2gDQSBMnTkwemzVrVjRPPTfb2toKr1Ev7e3tyWOLFi3q9fUhVxdccEG/ug7w23beeefksW9+85vRPPX7/F/91V8VXv/ZZ58tdK1bbrml8Bpl4E0hAAAAgAxpCgEAAABkSFMIAAAAIEOaQgAAAAAZ0hQCAAAAyFClWq1WN/dF69atS07z6guf+tSnonmtKV+HHXZYNB88eHA033PPPYsX1gcqlUo0v+2226L5eeedF803btyYXOPVV18tXFfZrF27NgwdOrTRZTRMo/dwM0ntvdS30nnz5iWvdccdd9SlphzkvIdz2L/d+FGkaaUmkzXTVLKc928IeezhvvDggw9G876YIFhrP9aaLtgsct7D9m8xe+yxRzT/0z/902h+8sknJ6+1ww471KOkHvnwww+j+dFHHx3NFy5c2JvlbJHu7F9vCgEAAABkSFMIAAAAIEOaQgAAAAAZ0hQCAAAAyJCmEAAAAECGBjW6gO449dRTo/nUqVP7uJK+t379+mje2toazSdPnhzNp0yZklzjjDPOiOZ33XXXZqqD/Bx33HHRPDU96YgjjkheKzV9rNZ+hTK74IILGl1Cv5OanNRM08egiP44jbDWhLPU9zXf7yi7vfbaK3ns1ltvjeapiWG77rprPUoKIYTw3HPPRfNXXnklmh955JHJaw0aFG+HbLXVVtF866233kx15eRNIQAAAIAMaQoBAAAAZEhTCAAAACBDmkIAAAAAGdIUAgAAAMiQphAAAABAhkoxkv7ggw8ufM5bb70VzT/66KNoft9990XzpUuXFl475fbbb4/my5cvT56TGsuZ+hzf+MY3ovmyZcuSa9x2223R/HOf+1w0//d///fktaDZrV69OprvtNNO0Xy77bZLXiu1X5csWRLNr7/++s1UB/3brFmz6nat1Mj2xYsXR/N6jodOjadOfb5a46xT56Q+n1H1NIu+GD0/e/bsaJ76fvDggw9G81p7GMrurLPOiuZTp05NnjN69OhCa6xduzaav/jii8lzbr755mie+p06pdYaqZH069evj+Zr1qwptHZZeFMIAAAAIEOaQgAAAAAZ0hQCAAAAyJCmEAAAAECGNIUAAAAAMlSK6WNXXXVV4XPuvffeaJ76m8+bxY033hjNP/nJTybPaWtri+a77rprNDd9jJylJh782Z/9WeFrpSavFJ2qAGVRqVSieWoSUD0nhtVT0clgPZmylJp2ZPoYZVLPqV2pez81YazWOSmp6YU9mSDYX79/ka999tknmp9yyinRvOiEsRBCePjhh6P5eeedF81TE3drSf0sceWVV0bzWpOAU5544olo/sgjjxS+Vhl4UwgAAAAgQ5pCAAAAABnSFAIAAADIkKYQAAAAQIY0hQAAAAAyVIrpYz/60Y8aXQJACCE9JeGkk06K5qkJCbV0dnYWPgfKrFmm9NTzczTLnwl5qzX9q729PZqnJn3ZE7Blxo0bF81/53d+p/C1UpO+r7jiimjekyljKUOHDo3mf/EXf1H4Wh999FE0v/XWWwtfq8y8KQQAAACQIU0hAAAAgAxpCgEAAABkSFMIAAAAIEOaQgAAAAAZKsX0MRrjnHPOieb/+q//Gs03bNjQm+VAv/DCCy9E82q1WvhaPTkHaLzUdKRZs2YVvtbs2bO3sBoop9RksloTy4Ceu++++6L5+eefX/hal156aTTftGlT4WulDBs2LJo/8MADdVvj1FNPjeY//OEP67ZGGXhTCAAAACBDmkIAAAAAGdIUAgAAAMiQphAAAABAhjSFAAAAADKkKQQAAACQISPpM7HTTjsVPufAAw+M5tttt100N5KenFUqlUJ5CCF0dnb2VjlAL+rJ6Hmg/2tra2t0CdBr3n777Wh+ySWX9HElvzFy5MjksXvuuSeaH3DAAYXWmDNnTvLYHXfcUehazcqbQgAAAAAZ0hQCAAAAyJCmEAAAAECGNIUAAAAAMqQpBAAAAJAh08eazMc//vFoPmXKlMLXWrlyZTT/4IMPCl8LmsVxxx0XzavVauFr3X777VtYDdCbLrjggmg+ceLEQtdpb29PHlu0aFGhawFbrl57O4QQZs+evWXFQMZqTQYrOmXs6quvjubTpk1LntPV1VVojWblTSEAAACADGkKAQAAAGRIUwgAAAAgQ5pCAAAAABnSFAIAAADIkOljTeass86K5oMHDy58re9973vRfO3atYWvBc3i+OOPj+aVSqVQDvQPtaYNzZo1q9C1UpPETBiD7kvtyXruo7a2trpdy/6G3xg1alQ0v+GGG6L5IYccUniN5557Lppfdtll0dyEsc3zphAAAABAhjSFAAAAADKkKQQAAACQIU0hAAAAgAxpCgEAAABkqNTTx7bZZpvksbPPPjuaDx8+vG7rn3TSSdH83Xffjebz5s0rvMY111wTzSdNmhTNJ0+eHM1rTUD64IMPovnChQs3Ux3k59Of/nQ0r1arfVwJUMQFF1wQzYtOGAshhNmzZxdaA5rdgw8+GM1rTfcDymvkyJHR/J//+Z+j+ec///nCazz99NPRPPV78Ouvv154DX7Nm0IAAAAAGdIUAgAAAMiQphAAAABAhjSFAAAAADKkKQQAAACQIU0hAAAAgAyVYiR9avT89ddfnzzn61//em+Vs1lDhgyJ5lOnTi18rdNPPz2aFx1/Xevrn3jiiWj+5JNPFloDclCpVOr29UuWLNnScoD/xeh52HKpUfKp0fM5K/pnsmjRomie+n5T6xzoTcOGDUseu+eee6L5AQccUGiN1Nj5EEI49thjo/ny5csLrcHmeVMIAAAAIEOaQgAAAAAZ0hQCAAAAyJCmEAAAAECGNIUAAAAAMlSK6WOjRo2K5o2cMNZMxo4dG80nT54czW+55ZbeLAf6tdQkv6ITAUMI4YUXXtjSciBb9ZoyVmvijyljNLPUhLEQ6jdlrNbUrMWLFxe6VltbWzSv9Tn6o1S9tT5H0YllppVRxAknnBDNzzzzzOQ5RaeMvfTSS9F80qRJyXNMGes73hQCAAAAyJCmEAAAAECGNIUAAAAAMqQpBAAAAJAhTSEAAACADJVi+lg9LVy4MJpfffXV0XzbbbdNXuvee++N5oMGxf9Y58+fH80PPvjg5BqVSiWapyYdvf/++9F8yJAhyTVSn3Hu3LnJc2JMJSMHqT2Z8u677/boGOQkNXWn1iSxohOH2tvbo7kpPeSqXhPGQij+bOyJnkztKir1/SD1/aPW+j35vlavNVJTyUxUzNuOO+4YzadNmxbN999//7qt/dprr0Xzsk0YGzlyZDRvbW1NnvPUU0/1Vjl1400hAAAAgAxpCgEAAABkSFMIAAAAIEOaQgAAAAAZ0hQCAAAAyFB208eGDh0azX/xi19E887OzuS1JkyYEM1POOGEaF5rylhKasrYT37yk2g+c+bMaL7XXnsl1zjrrLOi+T777BPNi04lC8FkMsrlK1/5SvJYak+m8hdffDF5rVrHoBmlJuX0ZApST6YEAVumkfurJ1O7Uur5/SN1raJ5rSlqbW1thc5J/VmZPpaH1NSw1LN2u+22681yQggh/P7v/340r7Xniv5skPrd/IADDkieM3369Gg+fPjwaJ6atDhw4MDkGjNmzIjmqennjeBNIQAAAIAMaQoBAAAAZEhTCAAAACBDmkIAAAAAGdIUAgAAAMiQphAAAABAhkoxkr6joyOaL1myJHnOIYccEs0PPPDAaH777bdH89WrVyfX+PKXvxzNBw2q3x9ramxlauz922+/Hc1//vOfJ9d49NFHC+U77bRTNE+N9AvBSHrKZeTIkcljqVGUwG+kxsjWGrkck3oGhtD8o+dTo6ONlKaRau3JeqlWq72+xuLFi3t9jZSio+pr8f0gX1/84heTx84///xo3hej51NSI9vnzZuXPOfHP/5xND/qqKOi+Q477BDNd9xxx9rF1UGt7ylz587t9fW3lDeFAAAAADKkKQQAAACQIU0hAAAAgAxpCgEAAABkSFMIAAAAIEOlmD72/vvvR/PTTjstec5PfvKTaD5ixIho/vnPf754YQVt2rQpms+ZMyd5zowZM6L5u+++W5eaQgjh5ZdfjubHHHNMNF+wYEE033vvvZNrpCaZHXvssdH8zTffTF4LGik1FaUvpqVAf5KaMBZC8SljKf11wlg9J/60tbVF89SfYT0nF0FRRafi1dorqXu/nmbPnh3Nm2VqV7N8DkIYPXp0NP/DP/zDaH7RRRclrzVkyJBCa//yl7+M5jfeeGPynNTv2tdcc000/+xnPxvNd9lll+Qa3/rWt5LHetvatWuj+cKFC6N5rb7EmjVr6lFSr/KmEAAAAECGNIUAAAAAMqQpBAAAAJAhTSEAAACADGkKAQAAAGSoFNPHUp599tnkseuuuy6an3rqqdF85MiRdakphBBWrlwZze+4445o/u1vf7tua9fTY489Fs1TE9G+//3vJ6914IEHRvPU31w/bty4zVQHvadSqSSPDRgQ76V3dXVF8x/+8Id1qQlyVM+pfqnpXPWalAZlk5rMFUIIs2bNqkveF2p9DtO5KIvU74Nnnnlm3dZ46qmnonlqGvRrr71WeI3UVLTvfOc70Xz33XdPXmvw4MHRPDUtLSX1O20IIdx+++3RfPXq1YWvVWbeFAIAAADIkKYQAAAAQIY0hQAAAAAypCkEAAAAkCFNIQAAAIAMlXr6WC0XXnhhNJ83b140/+xnPxvNTzjhhOQaP/jBD6L5E088Ec07OjqS1yqTuXPnRvPp06cnz0n9zfL33ntvXWqCeqo18Sg1ZSx1Tj2nJ0F/0t7enjz24IMPRvNGTvrqr1PGUlPRFi9eXOjroaieTObqiyljqWliqXvfnqAZTJs2LZqnfo7cuHFj8lrPPPNMNP/a174WzXsyZSxl/vz5hfIvfvGLyWsNGzYsmt96663FC6MmbwoBAAAAZEhTCAAAACBDmkIAAAAAGdIUAgAAAMiQphAAAABAhjSFAAAAADLUtCPpU371q18Vym+55ZbeLKeU3n///Wh+wAEHJM/Zfvvto/nKlSvrUhPUU6VSSR4bMCDeS0+Nqn/zzTfrUhOUSWpcfU9GYKe0tbVF83qOnk+Nui46MhvKpl57tdaesF/gNxYsWBDNv/SlL0Xzb3/728lr/d3f/V1dauoLDzzwQKNLIHhTCAAAACBLmkIAAAAAGdIUAgAAAMiQphAAAABAhjSFAAAAADKU3fQxek9nZ2ePjkF/89xzzyWPpaaMXXLJJdH8jjvuqEtN0AzqOX0M6Hv2MPSOo446qtElkDFvCgEAAABkSFMIAAAAIEOaQgAAAAAZ0hQCAAAAyJCmEAAAAECGTB8D+F+WLFmSPDZw4MA+rAQAAKD3eFMIAAAAIEOaQgAAAAAZ0hQCAAAAyJCmEAAAAECGNIUAAAAAMqQpBAAAAJAhTSEAAACADGkKAQAAAGRIUwgAAAAgQ5pCAAAAABnSFAIAAADIkKYQAAAAQIY0hQAAAAAypCkEAAAAkCFNIQAAAIAMaQoBAAAAZEhTCAAAACBD3WoKVavV3q4DelXu93Dun5/yy/kezvmz0xxyv4dz//yUX873cM6fnebQnXu4W02h9evXb3Ex0Ei538O5f37KL+d7OOfPTnPI/R7O/fNTfjnfwzl/dppDd+7hSrUbraOurq7Q0dERWlpaQqVSqUtx0Beq1WpYv359aG1tDQMG5Pt/S9rDlJU9bP9SXvbvr9nDlJU9bP9SXkX2b7eaQgAAAAA0lzxbvgAAAACZ0xQCAAAAyJCmEAAAAECGNIUAAAAAMqQpBAAAAJAhTSEAAACADGkKAQAAAGTo/wA8ArQ/hjAjngAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1500x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "for idx in np.arange(10):\n",
    "    ax = fig.add_subplot(2, 5, idx+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(X_train[idx].numpy()), cmap='gray')\n",
    "    ax.set_title(str(y_train[idx].item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "X2el3UpD6cYO",
   "metadata": {
    "id": "X2el3UpD6cYO"
   },
   "source": [
    "### 2.5 Preprocess the samples and initialize $\\mathbf{w}$ **(0.4 pts)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8531c05a-28a8-4309-98d2-b278e43be21f",
   "metadata": {
    "id": "8531c05a-28a8-4309-98d2-b278e43be21f"
   },
   "source": [
    "The original algorithm starts from zero parameter vector, but actually we can use just randomly initialized vector; it will make it faster to converge\n",
    "\n",
    "**Instructions**: Complete the missing lines of code and calculate the performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2a71993e-91fe-45af-bb58-040bbfd0cc40",
   "metadata": {
    "id": "2a71993e-91fe-45af-bb58-040bbfd0cc40"
   },
   "outputs": [],
   "source": [
    "def prep_data(X_train):\n",
    "    \"\"\"\n",
    "    Flatten, normalize and extra column for bias\n",
    "    Args:\n",
    "        X_train: np.array of shape (N, 28, 28)\n",
    "\n",
    "    Returns:\n",
    "        X: preprocessed data\n",
    "    \"\"\"\n",
    "    # Flatten the images\n",
    "    X = X_train.reshape(X_train.shape[0], -1)  # Reshape to (N, 784)\n",
    "\n",
    "    # Normalize the pixel values \n",
    "    X = X / 255.0\n",
    "\n",
    "    # Add a column for bias \n",
    "    bias_column = np.ones((X.shape[0], 1))  # Column of ones\n",
    "    X = np.hstack((bias_column, X))  # Append bias column to the left\n",
    "\n",
    "    return X\n",
    "\n",
    "def initialize_weight_vector(size):\n",
    "    \"\"\"\n",
    "    Create random parameter vector\n",
    "    Args:\n",
    "        size: Number of elements\n",
    "\n",
    "    Returns:\n",
    "        W: np.array of shape (size)\n",
    "    \"\"\"\n",
    "    W = np.random.randn(size)  # Using normal distribution with mean 0 and variance 1\n",
    "\n",
    "    return W\n",
    "\n",
    "def misclassified(X, y, W):\n",
    "    \"\"\"\n",
    "    Calculate indices of misclassified points\n",
    "    Args:\n",
    "        X: np.array, training images\n",
    "        y: np.array, training labels\n",
    "        W: np.array, parameter vector\n",
    "\n",
    "    Returns:\n",
    "        M: np.array of shape (m,) - indices of misclassified points, where m is a number of misclassified points\n",
    "    \"\"\"\n",
    "    predictions = np.dot(X, W)\n",
    "\n",
    "    binary_predictions = np.where(predictions >= 0, 1, -1)\n",
    "    \n",
    "    misclassified_indices = np.where(binary_predictions != y.numpy())[0]\n",
    "\n",
    "    return misclassified_indices\n",
    "\n",
    "\n",
    "X_train_flat_aug = prep_data(X_train)\n",
    "X_test_flat_aug = prep_data(X_test)\n",
    "\n",
    "W = initialize_weight_vector(X_train_flat_aug.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c942c8e-1a2b-47f0-af9a-8ac09905c8d4",
   "metadata": {
    "id": "4c942c8e-1a2b-47f0-af9a-8ac09905c8d4"
   },
   "source": [
    "### 2.6 Training loop **(0.5 pts)**\n",
    "Here you need to complete the training loop of the PLA algorithm. Observe that recalculation the misclassified set (Step 3 of the PLA algorithm) is the most costly (as we need to iterate through the whole train set). To speed up the algorithm convergence, we will do the following:\n",
    "-  determine the set $S$ of misclassified datapoints\n",
    "-  for every $\\mathbf{w}\\in S$ that is still misclassified, update the vector $\\mathbf{w}$\n",
    "-  only after that recalculate the set $S$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ac792433-7ba8-483a-929f-c10fe0353b86",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ac792433-7ba8-483a-929f-c10fe0353b86",
    "outputId": "e0e5afe8-845a-4fb1-844e-f456798916a5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISSCLASIFIED DIST\n",
      "{-1: 356, 1: 1139}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 1333}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 1495}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 262, 1: 26}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 77, 1: 70}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 67, 1: 64}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 58, 1: 53}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 55, 1: 53}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 49, 1: 49}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 46, 1: 45}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 44, 1: 41}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 36, 1: 38}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 35, 1: 36}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 30, 1: 34}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 30, 1: 31}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 30, 1: 31}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 29, 1: 30}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 29, 1: 30}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 25, 1: 29}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 24, 1: 29}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 24, 1: 29}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 25, 1: 29}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 25, 1: 28}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 24, 1: 26}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 21, 1: 26}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 23, 1: 24}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 21, 1: 24}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 22, 1: 23}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 22, 1: 23}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 22, 1: 24}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 22, 1: 23}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 21, 1: 23}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 21, 1: 21}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 16, 1: 22}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 20, 1: 20}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 19, 1: 20}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 19, 1: 21}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 18, 1: 20}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 18, 1: 21}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 18, 1: 20}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 18, 1: 20}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 17, 1: 21}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 17, 1: 20}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 17, 1: 18}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 17, 1: 18}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 16, 1: 18}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 18}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 16, 1: 18}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 14, 1: 18}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 16, 1: 18}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 16, 1: 17}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 14, 1: 17}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 16, 1: 17}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 17}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 17}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 17}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 16, 1: 17}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 16}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 16, 1: 16}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 16}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 16}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 14, 1: 16}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 15}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 14, 1: 17}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 15}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 14, 1: 16}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 16}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 16}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 14, 1: 16}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 15}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 14, 1: 16}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 15}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 14, 1: 16}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 14}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 13, 1: 16}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 14, 1: 14}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 14, 1: 15}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 13, 1: 15}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 14}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 13, 1: 16}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 14}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 14, 1: 16}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 14}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 13, 1: 16}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 14}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 13, 1: 16}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 14}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 14, 1: 16}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 15}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 13, 1: 16}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 14}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 13, 1: 15}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 14}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 13, 1: 16}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 14}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 12, 1: 16}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 13}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 12, 1: 16}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 12}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 12, 1: 16}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 12}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 12, 1: 16}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 12}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 11, 1: 16}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 12}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 11, 1: 15}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 12}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 11, 1: 15}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 12, 1: 12}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 11, 1: 13}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 13}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 10, 1: 14}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 13, 1: 13}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 10, 1: 13}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 14, 1: 12}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 8, 1: 14}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 8, 1: 14}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 13, 1: 12}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 9, 1: 12}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 10, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 9, 1: 12}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 12, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 9, 1: 12}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 11, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 9, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 9, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 10, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 9, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 9, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 12, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 8, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 9, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 7, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 10, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 8, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 8, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 7, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 10, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 6, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 11, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 6, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 9, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 7, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 8, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 8, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 8, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 7, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 11, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 5, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 13, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 10, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 7, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 8, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 8, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 7, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 10, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 5, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 12, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 5, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 10, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 7, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 9, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 6, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 12, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 12, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 6, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 9, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 8, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 7, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 10, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 5, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 12, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 5, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 10, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 7, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 9, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 6, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 13, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 5, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 11, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 7, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 9, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 6, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 13, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 3, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 11, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 8, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 10, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 5, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 13, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 3, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 12, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 5, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 10, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 8, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 8, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 6, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 13, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 3, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 10, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 10, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 3, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 14, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 3, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 13, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 5, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 11, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 6, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 12, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 14, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 3, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 13, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 12, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 8, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 8, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 10, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 6, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 12, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 14, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 3, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 14, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 6, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 11, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 7, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 12, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 5, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 13, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 5, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 14, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 3, 1: 13}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 17, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 12}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 14, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 5, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 13, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 5, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 14, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 13}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 5, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 13, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 6, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 14, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 12}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 16, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 12}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 13, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 6, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 13, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 5, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 14, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 12}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 12}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 16, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 13, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 6, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 13, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 6, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 11, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 10, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 10, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 9, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 7, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 2, 1: 13}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 18, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 3, 1: 12}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 12, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 5, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 13, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 12, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 5, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 10, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 9, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 5, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 10, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 6, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 16, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 3, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 11, 1: 8}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 8}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 3, 1: 12}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 13, 1: 7}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 10, 1: 8}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 5, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 12, 1: 7}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 6}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 2, 1: 12}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 9, 1: 6}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 6}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 2, 1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 8, 1: 6}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 5, 1: 7}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 6, 1: 7}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 8, 1: 6}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 12, 1: 6}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 3, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 8, 1: 6}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 5, 1: 7}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 7, 1: 6}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 8}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 12, 1: 6}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 2, 1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 6}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 6}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 9, 1: 6}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 5, 1: 7}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 6, 1: 6}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 6, 1: 6}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 5, 1: 7}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 7, 1: 6}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 3, 1: 8}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 13, 1: 5}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 16, 1: 5}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 7, 1: 6}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 6, 1: 6}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 3, 1: 6}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 8, 1: 6}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 1, 1: 7}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 17, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 6, 1: 6}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 2, 1: 6}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 9, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 1, 1: 8}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 11, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 8}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 8, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 1, 1: 6}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 6, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 2, 1: 5}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 3, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 5, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 1, 1: 5}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 10, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 8}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 13, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 10}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 10, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 6}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 2, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 5, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 2, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 5, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 5}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 16, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 7, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 5}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 12, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 2, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 9, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 5}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 2, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 6, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 16, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 2, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 10, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 8}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 8, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 5}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 9, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 5}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 2, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 7, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 9, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 5}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 5, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 1, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 13, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 8}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 2, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 20, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 12}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 5}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 14, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 8}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 1, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 8, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 6}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 6, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 14, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 8}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 2, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 2, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 9, 1: 3}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 6}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 2, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 9, 1: 3}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 6}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 2, 1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 15, 1: 2}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 2}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 10, 1: 2}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 6}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 12, 1: 2}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 8}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 3}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 11, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 7}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 8, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 6}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 2, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 2}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 13, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 2}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 2, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 1, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 6, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 1, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 2, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 5, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 3}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 1, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 2}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 3, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 10, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 6}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 1, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 2}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 3, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 1, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 3}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 8, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 5}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 9, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 7}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 2}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 9, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 6}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 8, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 6}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 1, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 9, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 5}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 2, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 8, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 4}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 10, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 12, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 1, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 9, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 3}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 2, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 6, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 2}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 2}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 6, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 2}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 2}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 3, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 4, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 3}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 6, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 5}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 12, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 11}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 9, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 10, 1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 9}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 1}\n",
      "MISSCLASIFIED DIST\n",
      "{-1: 5}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 2}\n",
      "MISSCLASIFIED DIST\n",
      "{1: 1}\n",
      "Found separating hyperplane on step 540!\n"
     ]
    }
   ],
   "source": [
    "def loop(X_train_flat_aug, y_train):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        W: the final vector of weights for the separating hyperplane\n",
    "    \"\"\"\n",
    "    W = initialize_weight_vector(X_train_flat_aug.shape[1])\n",
    "\n",
    "    for i in range(1000):\n",
    "        misclass = misclassified(X_train_flat_aug, y_train, W)\n",
    "        if len(misclass) == 0:\n",
    "            print(f\"Found separating hyperplane on step {i}!\")\n",
    "            break\n",
    "\n",
    "        unique, counts = np.unique(y_train[misclass], return_counts=True)\n",
    "        value_counts = dict(zip(unique, counts))\n",
    "        print(value_counts)\n",
    "\n",
    "        for m in misclass:\n",
    "            x_misclass = X_train_flat_aug[m]\n",
    "            y_misclass = y_train[m]\n",
    "\n",
    "            \n",
    "            W = np.add(W, np.multiply(y_misclass, x_misclass))  # Update weights using element-wise multiplication and addition\n",
    "\n",
    "    return W\n",
    "\n",
    "W = loop(X_train_flat_aug, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151d7f57-bdec-4b35-9bca-22778c7778e9",
   "metadata": {
    "id": "151d7f57-bdec-4b35-9bca-22778c7778e9"
   },
   "source": [
    "### 2.7 Evaluate performance of the linear classifier on the test set **(0.3 pts)**\n",
    "\n",
    "Check your classifier on the test set. Think of possible metrics that characterize performance and comment on how good the classifier is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ea11a6c7-e4a3-439d-a836-19455f3d643a",
   "metadata": {
    "id": "ea11a6c7-e4a3-439d-a836-19455f3d643a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9832109129066107\n",
      "Precision: 0.9832270793047466\n",
      "Recall: 0.9832109129066107\n",
      "F1-score: 0.9832013522660364\n",
      "Confusion Matrix:\n",
      "[[405  10]\n",
      " [  6 532]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def evaluate_classifier(X_test_flat_aug, y_test, W):\n",
    "    predictions = np.dot(X_test_flat_aug, W)\n",
    "    binary_predictions = np.where(predictions >= 0, 1, -1)\n",
    "    accuracy = accuracy_score(y_test, binary_predictions)\n",
    "    precision = precision_score(y_test, binary_predictions, average='weighted')  # Change average to 'weighted'\n",
    "    recall = recall_score(y_test, binary_predictions, average='weighted')  # Change average to 'weighted'\n",
    "    f1 = f1_score(y_test, binary_predictions, average='weighted')  # Change average to 'weighted'\n",
    "    confusion = confusion_matrix(y_test, binary_predictions)\n",
    "\n",
    "    return accuracy, precision, recall, f1, confusion\n",
    "\n",
    "# Usage:\n",
    "accuracy, precision, recall, f1, confusion_matrix = evaluate_classifier(X_test_flat_aug, y_test, W)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xq-iaKD2jgYU",
   "metadata": {
    "id": "xq-iaKD2jgYU"
   },
   "source": [
    "## 3. Conclusions **(0.3 pts)**\n",
    "\n",
    "Summarize in a few sentences what you have learned and achieved by completing the tasks of this assignment\n",
    "\n",
    "\n",
    "\\### **YOUR ANSWER HERE** \\###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42228740",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
